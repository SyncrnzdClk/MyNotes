# kNN

k近邻模型实际上并没有显式的学习过程，他的策略就是对输入点周围的k个最近的训练点进行分析，根据某些原则（比如多数表决）来判断输入点的标签。这样的模型看似是比较简单的，但是实际上所谓的“最近”还并没有一个确定的方式度量。比较自然的想法是$L_p$范数，但是实际上，我们用来训练的数据点中可能受一些噪声的影响，导致有些情况下标签不同的点反而离得更近（在$L_p$范数下的度量）。此时我们可能可以利用一些线性变换，先将数据点的位置移动到合理的位置，也就是让标签相同的数据离得更近，标签不同的数据离得更远。

## strategy
通过寻找目标点最近的k个点，然后利用多数表决的原则对目标点进行分类。

## decision by majority
这里想提一句的是多数表决原则实际上就是经验概率最大化。

## about k
k的值越大，决策数据集越接近全集，这时候离实例点很远的点也可能会对判断产生影响。

k的值越小，决策数据集受到噪声的影响就更大，比如离目标点最近的点如果是一个噪声，那么目标点就会被错误标签。但是测试数据集如果和训练数据集很近的话，那么效果比较好。

所以k的选择还是要根据实际而定。